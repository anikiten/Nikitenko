[CRAB]

jobtype = cmssw

scheduler  = glite

# use_server = 1

# server_name  = cern

[CMSSW]

### The data you want to access (to be found on DBS)

# files with PU data distributions are in:
# https://cms-service-dqm.web.cern.ch/cms-service-dqm/CAF/certification/Collisions11/7TeV/PileUp/
# 44X
# /DoubleMu/Run2011A-08Nov2011-v1/AOD
# /DoubleMu/Run2011B-19Nov2011-v1/AOD
# 

#
############################## for VBF #################################################
#
# PU profile data histos can be found on
# /afs in /afs/cern.ch/cms/CAF/CMSCOMM/COMM_DQM/certification/Collisions11/7TeV/PileUp/
#
# PVT  160329-163869
# Cert_160404-163869_7TeV_May10ReReco_Collisions11_JSON_v3.pileup_v2.root
# datasetpath=/DoubleMu/Run2011A-May10ReReco-v1/AOD
# lumi_mask = Cert_160404-163869_7TeV_May10ReReco_Collisions11_JSON_v3.txt

# PVT  165071-168437
# Cert_165088-167913_7TeV_PromptReco_JSON.pileup_v2.root
datasetpath=/DoubleMu/Run2011A-PromptReco-v4/AOD
lumi_mask = Cert_160404-180252_7TeV_PromptReco_Collisions11_JSON.txt 

# datasetpath=/DoubleMu/Run2011A-05Aug2011-v1/AOD
# PVT  170053-172619 
# Cert_170249-172619_7TeV_ReReco5Aug_Collisions11_JSON_v2.pileup_v2.root 
# lumi_mask = Cert_170249-172619_7TeV_ReReco5Aug_Collisions11_JSON_v3.txt
# 

# datasetpath=/DoubleMu/Run2011A-PromptReco-v6/AOD
# PVT  172620-175770
# Cert_172620-173692_PromptReco_JSON.pileup_v2.root  
# lumi_mask = Cert_160404-180252_7TeV_PromptReco_Collisions11_JSON.txt 
#
#
#
# datasetpath=/DoubleMu/Run2011B-PromptReco-v1/AOD
# PVT  175832-180296 
# Cert_175832-177515_PromptReco_JSON.pileup_v2.root +
# Cert_177718_178078_7TeV_PromptReco_Collisons11_JSON.pileup_v2.root +
# Cert_178098-180252_7TeV_PromptReco_Collisions11_JSON.pileup_v2.root  
# lumi_mask = Cert_160404-180252_7TeV_PromptReco_Collisions11_JSON.txt
#########################################################################################


### Total number of events to be accessed: -1 means all ("-1" is not usable if no input)

total_number_of_lumis = -1

lumis_per_job = 500

pset=DiMuAnalysis_Data_cfg.py

# The output files produced by your application (comma separated list)
output_file = DiMuAnalysis_Data.root

[USER]

# check_user_remote_dir = 0

#
#additional_input_files = /home_local/fanzago/fede.txt, ....
#
#ui_working_dir = /afs/cern.ch/user/a/anayak/scratch0/CMS/CRAB/test

#################################
#### JOB OUTPUT MANAGEMENT #####
##########################q#######

return_data = 0

copy_data = 1

storage_element=srm-cms.cern.ch
storage_path = /srm/managerv2?SFN=/castor/cern.ch
# user_remote_dir = /user/a/anikiten/DiMuonData2012Jan27May10ReReco
user_remote_dir = /user/a/anikiten/DiMuonData2012Jan27V4
email = Alexandre.Nikitenko@cern.ch


## the SE directory (or the mountpoint) that has to be writable from all
##(imp : Castor directory should be made public to store output root files,
##       using "rfchmod 775 dirName")
##  rfchmod 775 /castor/cern.ch/user/a/anikiten
##  rfchmod 775 /castor/cern.ch/user/a/anikiten/DiMuonData2011Sept14
##  rfchmod 775 /castor/cern.ch/user/a/anikiten/DiMuonData2011Oct5
##  rfchmod 775 /castor/cern.ch/user/a/anikiten/DiMuonData2011nov10
##  rfchmod 775 /castor/cern.ch/user/a/anikiten/DiMuonData2012Jan27May10ReReco
##  rfchmod 775 /castor/cern.ch/user/a/anikiten/DiMuonData2012Jan27V4

[GRID]
## WMS to use

rb = CERN

proxy_server  = myproxy.cern.ch

virtual_organization    = cms

retry_count             = 2

lcg_catalog_type        = lfc

lfc_host                = lfc-cms-test.cern.ch

lfc_home                = /grid/cms

##  Black and White Lists management:
## by SE 
#se_black_list =
#se_white_list =
## by CE
#ce_black_list =
#ce_white_list =

## Role in VOMS
#role = superman
## Group in VOMS
#group = superheros

## cpu time and wall_clock_time(=real time) in minutes. Written into the jdl file
#max_cpu_time = 60
#max_wall_clock_time = 60


